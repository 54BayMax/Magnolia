{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Lab41's monaural source separation model\n",
    "\n",
    "This notebook contains a detailed example of how to train Lab41's source separation model.  Filepaths to load training data must be filled in to run this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Generic imports\n",
    "import sys\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "# Plotting imports\n",
    "import IPython\n",
    "from IPython.display import Audio\n",
    "from matplotlib import pyplot as plt\n",
    "fig_size = [0,0]\n",
    "fig_size[0] = 8\n",
    "fig_size[1] = 4\n",
    "plt.rcParams[\"figure.figsize\"] = fig_size\n",
    "\n",
    "# Import Lab41's separation model\n",
    "from magnolia.dnnseparate.L41model import L41Model\n",
    "\n",
    "# Import utilities for using the model\n",
    "#from magnolia.utils.clustering_utils import clustering_separate, get_cluster_masks, process_signal\n",
    "#from magnolia.iterate.supervised_iterator import SupervisedIterator, SupervisedMixer\n",
    "#from magnolia.iterate.hdf5_iterator import SplitsIterator\n",
    "from magnolia.iterate.mix_iterator import MixIterator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameters\n",
    "\n",
    "* **batchsize**      : Number of examples per batch used in training\n",
    "* **train_mixes**    : List of mix configuration settings used for training (total number of signals and noises must be two in all mixes)\n",
    "* **validate_mixes** : List of mix configuration settings used for validation (total number of signals and noises must be two in all mixes)\n",
    "* **model_save_path**: Directory to store the saved models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batchsize = 256\n",
    "train_mixes = ['/local_data/magnolia/pipeline_data/date_2017_09_27_time_13_25/settings/mixing_LibriSpeech_UrbanSound8K_train.json']\n",
    "train_from_disk = True\n",
    "validate_mixes = ['/local_data/magnolia/pipeline_data/date_2017_09_27_time_13_25/settings/mixing_LibriSpeech_UrbanSound8K_validate.json']\n",
    "validate_from_disk = True\n",
    "model_save_path = '/local_data/magnolia/experiment_data/date_2017_09_28_time_13_14/aux/model_saves'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create an mixer that iterates over examples from the training and validation sets. \n",
    "\n",
    "MixIterator takes a list a `mix_data.py` setting JSON file names and constructs an iterator that will loop over all the mixes samples in the specified list.\n",
    "\n",
    "Here, we'll create two separate iterators, one for the training mixes and another for the validation mixes.\n",
    "\n",
    "The `MixIterator` class will automatically reset whenever it's reached the end of it's epoch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'tuple' object has no attribute 'shape'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-daeda046f5ab>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_mixer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'tuple' object has no attribute 'shape'"
     ]
    }
   ],
   "source": [
    "training_mixer = MixIterator(mixes_settings_filenames=train_mixes,\n",
    "                             batch_size=batchsize,\n",
    "                             from_disk=train_from_disk)\n",
    "\n",
    "validation_mixer = MixIterator(mixes_settings_filenames=validate_mixes,\n",
    "                               batch_size=batchsize,\n",
    "                               from_disk=validate_from_disk)\n",
    "\n",
    "batch = next(training_mixer)\n",
    "print(batch.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create an instance of Lab41's model\n",
    "\n",
    "Here an untrained model instance is created, and its variables are initialized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = L41Model(nonlinearity='tanh', normalize='False', device='/gpu:0')\n",
    "model.initialize()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Variables needed to track the training progress of the model\n",
    "\n",
    "During training, the number of iterations (number of processed batches) is tracked, along with the mean cost on examples from the training data and from the validation data.  The last iteration that the model was saved on can also be tracked."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nbatches = []\n",
    "costs = []\n",
    "\n",
    "t_costs = []\n",
    "v_costs = []\n",
    "\n",
    "last_saved = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Training loop\n",
    "\n",
    "Here the model is iteratively trained on batches generated by the mixer.  The model is saved every time the validation cost reaches a new minimum value.  The training can be configured to stop if the model has not been saved after a specified number of iterations have elapsed since the previous save.  Plots of the training cost and the validation set are created as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Number of epochs\n",
    "num_epochs = 2\n",
    "# Threshold for stopping if the model hasn't improved for this many consecutive batches\n",
    "stop_threshold = 10000\n",
    "\n",
    "# Find the number of batches already elapsed (Useful for resuming training)\n",
    "start = 0\n",
    "if len(nbatches) != 0:\n",
    "    start = nbatches[-1]\n",
    "\n",
    "batch_count = 0\n",
    "# Total training epoch loop\n",
    "for epoch_num in range(num_epochs):\n",
    "    \n",
    "    # Training epoch loop\n",
    "    for batch in iter(training_mixer):\n",
    "        # dimensions of (batch size, time frame, frequency)\n",
    "        spectral_sum_batch = batch[0].transpose(0, 2, 1)\n",
    "        # dimensions of (batch size, time frame, frequency, source)\n",
    "        spectral_masks_batch = batch[1].transpose(0, 3, 2, 1)\n",
    "        # dimensions of (batch size, source)\n",
    "        uids_batch = batch[3]\n",
    "        \n",
    "        # scale spectral inputs\n",
    "        spectral_sum_batch = np.sqrt(np.abs(spectral_sum_batch))\n",
    "        spectral_sum_batch = (spectral_sum_batch - spectral_sum_batch.min())/(spectral_sum_batch.max() - spectral_sum_batch.min())\n",
    "        # convert and scale {-1.0, 1.0} spectral masks\n",
    "        spectral_masks_batch = 2.0*spectral_masks_batch.astype(float) - 1.0\n",
    "        \n",
    "        # Train the model on one batch and get the cost\n",
    "        c = model.train_on_batch(spectral_sum_batch, spectral_masks_batch, uids_batch)\n",
    "        \n",
    "        # Store the training cost\n",
    "        costs.append(c)\n",
    "        \n",
    "        # Store the current batch_count number\n",
    "        \n",
    "        # Every 10 batches, evaluate the model on the validation data and plot the cost curves\n",
    "        if (batch_count + 1) % 10 == 0:\n",
    "            IPython.display.clear_output(wait=True)\n",
    "            \n",
    "            # Store the training cost\n",
    "            t_costs.append(np.mean(costs))\n",
    "            # Reset the cost over the last 10 batches\n",
    "            costs = []\n",
    "            \n",
    "            # Compute average validation score\n",
    "            all_c_v = []\n",
    "            for vbatch in iter(validation_mixer):\n",
    "                # dimensions of (batch size, time frame, frequency)\n",
    "                spectral_sum_batch = vbatch[0].transpose(0, 2, 1)\n",
    "                # dimensions of (batch size, time frame, frequency, source)\n",
    "                spectral_masks_batch = vbatch[1].transpose(0, 3, 2, 1)\n",
    "                # dimensions of (batch size, source)\n",
    "                uids_batch = vbatch[3]\n",
    "\n",
    "                # scale spectral inputs\n",
    "                spectral_sum_batch = np.sqrt(np.abs(spectral_sum_batch))\n",
    "                spectral_sum_batch = (spectral_sum_batch - spectral_sum_batch.min())/(spectral_sum_batch.max() - spectral_sum_batch.min())\n",
    "                # convert and scale {-1.0, 1.0} spectral masks\n",
    "                spectral_masks_batch = 2.0*spectral_masks_batch.astype(float) - 1.0\n",
    "\n",
    "                # Get the cost on the validation batch\n",
    "                c_v = model.get_cost(spectral_sum_batch, spectral_masks_batch, uids_batch)\n",
    "                all_c_v.append(c_v)\n",
    "            \n",
    "            ave_c_v = np.mean(all_c_v)\n",
    "            \n",
    "            # Check if the validation cost is below the minimum validation cost, and if so, save it.\n",
    "            if len(v_costs) > 0 and ave_c_v < min(v_costs) and len(nbatches) > 0:\n",
    "                print(\"Saving the model because validation score is \", min(v_costs) - ave_c_v, \" below the old minimum.\")\n",
    "                \n",
    "                # Save the model to the specified path\n",
    "                model.save(model_save_path)\n",
    "                \n",
    "                # Record the batch that the model was last saved on\n",
    "                last_saved = nbatches[-1]\n",
    "            \n",
    "            # Store the validation cost\n",
    "            v_costs.append(ave_c_v)\n",
    "            \n",
    "            # Store the current batch number\n",
    "            nbatches.append(batch_count + 1 + start)\n",
    "            \n",
    "            # Compute scale quantities for plotting\n",
    "            length = len(nbatches)\n",
    "            cutoff = int(0.5*length)\n",
    "            lowline = [min(v_costs)]*length\n",
    "        \n",
    "            # Generate the plots and show them\n",
    "            f, (ax1, ax2) = plt.subplots(2,1)\n",
    "        \n",
    "            ax1.plot(nbatches, t_costs)\n",
    "            ax1.plot(nbatches, v_costs)\n",
    "            ax1.plot(nbatches, lowline)\n",
    "        \n",
    "            y_u = max(max(t_costs[cutoff:]), max(v_costs[cutoff:]))\n",
    "            y_l = min(min(t_costs[cutoff:]), min(v_costs[cutoff:]))\n",
    "        \n",
    "            ax2.set_ylim(y_l, y_u)\n",
    "        \n",
    "            ax2.plot(nbatches[cutoff:], t_costs[cutoff:])\n",
    "            ax2.plot(nbatches[cutoff:], v_costs[cutoff:])\n",
    "            ax2.plot(nbatches[cutoff:], lowline[cutoff:])\n",
    "            plt.show()\n",
    "        \n",
    "            print(\"Cost on batch \", nbatches[-1], \" is \", ave_c_v, \".\")\n",
    "            print(\"Last saved \",nbatches[-1] - last_saved,\" batches ago.\")\n",
    "        \n",
    "            # Stop training if the number of iterations since the last save point exceeds the threshold\n",
    "            if nbatches[-1] - last_saved > stop_threshold:\n",
    "                print(\"Done!\")\n",
    "                break\n",
    "        \n",
    "        batch_count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "tensorflow1.1",
   "language": "python",
   "name": "tf1.1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

<html>
  <head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <!-- The above 3 meta tags *must* come first in the head; any other head content must come *after* these tags -->
    <meta name="description" content="">
    <meta name="author" content="">

    <!-- Bootstrap core CSS -->
    <link href="../static/css/bootstrap.min.css" rel="stylesheet">

    <!-- Custom styles for this template -->
    <link href="../static/css/jumbotron-narrow.css" rel="stylesheet">

    <title>{{ title }} - microblog</title>
  </head>
  
  <body>
    <div class="container">

      <div class="jumbotron">
        <h1>Magnolia</h1>
        <p class="lead">Blind signal separation (BSS), also known as blind source separation, is the separation of a set of source signals from a set of mixed signals, without the aid of information (or with very little information) about the source signals or the mixing process.</p>
        <script>
          function wavFileSubmit(){
            document.getElementById("submit_form").submit();
          }
        </script>

        <form id = "submit_form" action="/upload" method="post" enctype="multipart/form-data">
            <label class="btn btn-block btn-success btn-lg">
                Browse&hellip; <input type="file" style="display: none;" name="file" onchange="wavFileSubmit()">
            </label>
        </form>

        {% if input_sound is not none %}
          <audio controls>
          <source src="{{input_sound}}" type="audio/wav">
        </audio>
        {% endif %}
        <p> </p>

        {% if input_spec_url is not none %}
        <img src="/resources/{{input_spec_url}}" alt="spectogram" style="width:300px;height:300px;">
        {% endif %}

        <br></br>

        <div class="row">
          <div class="col-lg-3" >  
            <form action="/" method="post">
            <input class="btn btn-primary btn-lg full-width-elem" type = "submit" name="btn" value = "L41Net" style="background-color: #337ab7"/>
            </form>
          </div>  

          <div class="col-lg-3">  
            <form action="/" method="post">
            <input class="btn btn-primary btn-lg full-width-elem" type="submit" name="btn" value = "DeepNet" style="background-color: #d9534f"/>
            </form>
          </div>   

          <div class="col-lg-3">  
            <form action="/" method="post">
            <input class="btn btn-primary btn-lg full-width-elem" type="submit" name="btn" value = "PIT" style="background-color: #5bc0de"/>
            </form>
          </div> 

        <div class="col-lg-3">  
            <form action="/" method="post">
            <input class="btn btn-primary btn-lg full-width-elem" type="submit" name="btn" value = "NMF" style="background-color: #f0ad4e"/>
            </form>
          </div> 
        </div>

        <div class="row">
          {% for x in wav_files %}
          <div class="col-lg-6">
            <p>Speaker {{ loop.index }}</p>
          <audio controls class="full-width-elem">
            <source src="/resources/{{x}}" type="audio/wav">
          </audio>
          </div>
          {% endfor %}  
        </div>
        
      </div>
      
      <div class="row marketing justify-elem">
        <div class="row">
          <h4 class="col-lg-6" style="color:#337ab7;">L41Net</h4> 
          <h4 class="col-lg-6" style="color:#d9534f">DeepNet</h4>   
        </div>
        <div class="row">
          <p class="col-lg-6">This is a deep learning based algorithm that was developed by the Magnolia team. This algorithm builds upon the work of "<a href="https://arxiv.org/abs/1508.04306">Deep Clustering</a>" by using a more performant and optimal cost function. Our novel contribution is the use of speaker specific embeddings.</p>
          <p class="col-lg-6">This is a deep learning based algorithm that we reproduced from a paper titled "<a href="https://arxiv.org/abs/1508.04306">Deep Clustering</a>". The main idea behind this paper was to use frequency similarities as a means of embedding speakers in a higher dimensional space. This projection into an embedding space allows for easier speaker separation.</p>
        </div>
        <div class="row">
          <h4 class="col-lg-6" style="color:#5bc0de;">PIT</h4> 
          <h4 class="col-lg-6" style="color:#f0ad4e;">NMF</h4>   
        </div>
        <div class="row">
          <p class="col-lg-6">This is a deep learning based algorithm that we reproduced from a <a href="https://arxiv.org/abs/1703.06284">paper</a> that performed speaker separation via Permutation Invariant Training (PIT). PIT aims to minimize signal reconstruction error irrespective of how speaker labels are ordered. </p>
          <p class="col-lg-6">This is a linear based algorithm we reproduced called Non Negative Matrix Factorization (NMF). The objective of this algorithm is to identify key feature vectors that can later be reconstructed to separate speakers</p>
        </div>  
      </div>  
        
    </div> <!-- /container -->
  </body>
</html>

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sparse NMF for Separation\n",
    "\n",
    "One approach to using NMF for source separation is to learn sets of $k$ basis vectors $W$ and $H$ for each of the speakers in a dataset. To separate a mixture where the speakers are known, we concatenate the dictionaries $W$ associated with them, learn new loadings $H$, and take the product of the speaker-specific $W$ with the associated components of $H$ to yield the reconstruction.\n",
    "\n",
    "Training, for speaker $i$:\n",
    "$$X_i = W_i H_i$$\n",
    "$$W_i, H_i = \\text{NMF}(X_i)$$\n",
    "\n",
    "Evaluation, on mixture $X_{ij}$ of speech from speaker $i$ and $j$. $\\text{NMF}_W$ performs NMF updates without updating the values in $W$:\n",
    "$$W_{ij} = [ W_i \\, W_j ]$$\n",
    "$$H_{ij}' = \\text{NMF}_{W_{ij}}(X_{ij})$$\n",
    "$$H_{ij}' = [ H_i' \\, H_j' ]$$\n",
    "$$\\hat{X}_i = W_i H_i$$\n",
    "$$\\hat{X}_j = W_j H_j$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys \n",
    "from itertools import islice, permutations, product\n",
    "from collections import namedtuple\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import IPython.display as display\n",
    "\n",
    "from magnolia.features.hdf5_iterator import Hdf5Iterator\n",
    "from magnolia.features.mixer import FeatureMixer\n",
    "#from magnolia.features.wav_iterator import batcher\n",
    "from magnolia.utils.tf_utils import scope_decorator as scope\n",
    "from magnolia.utils.bss_eval import bss_eval_sources\n",
    "from magnolia.factorization.nmf import snmf, nmf_separate\n",
    "from magnolia.features.spectral_features import reconstruct\n",
    "\n",
    "num_srcs = 2\n",
    "num_steps = 80\n",
    "num_freq_bins = 257\n",
    "num_components = 20\n",
    "sparsity = 0.1\n",
    "\n",
    "# librispeech_dev = \"/local_data/teams/magnolia/librispeech/processed_dev-clean.h5\"\n",
    "# librispeech_train = \"/local_data/teams/magnolia/librispeech/processed_train-clean-100.h5\"\n",
    "librispeech_dev = \"/Users/patrickc/data/LibriSpeech/processed_dev-clean.h5\"\n",
    "\n",
    "def scale_spectrogram(spectrogram):\n",
    "    mag_spec = np.abs(spectrogram)\n",
    "    phases = np.unwrap(np.angle(spectrogram))\n",
    "    \n",
    "    mag_spec = np.sqrt(mag_spec)\n",
    "    M = mag_spec.max()\n",
    "    m = mag_spec.min()\n",
    "    \n",
    "    return (mag_spec - m)/(M - m), phases\n",
    "\n",
    "def moving_average(a, n=3):\n",
    "    ret = np.cumsum(a, dtype=float)\n",
    "    ret[n:] = ret[n:] - ret[:-n]\n",
    "    return ret[n - 1:] / n\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data\n",
    "### Get speaker-specific iterators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../../data/librispeech/authors/dev-clean-F.txt'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-47fc5fe77770>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"../../data/librispeech/authors/dev-clean-F.txt\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mfemale_dev\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'\\n'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mfemale_spkrs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mHdf5Iterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhdf5_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlibrispeech_dev\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mspeaker_keys\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdev\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mdev\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfemale_dev\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mfemale_spkrs_slice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mHdf5Iterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhdf5_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlibrispeech_dev\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mspeaker_keys\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdev\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mdev\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfemale_dev\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../../data/librispeech/authors/dev-clean-F.txt'"
     ]
    }
   ],
   "source": [
    "with open(\"../../data/librispeech/authors/dev-clean-F.txt\") as f:\n",
    "    female_dev = f.read().strip().split('\\n')\n",
    "\n",
    "female_spkrs = [Hdf5Iterator(hdf5_path=librispeech_dev, speaker_keys=[dev], shape=(None,)) for dev in female_dev]\n",
    "female_spkrs_slice = [Hdf5Iterator(hdf5_path=librispeech_dev, speaker_keys=[dev], shape=(num_steps,)) for dev in female_dev]\n",
    "\n",
    "with open(\"../../data/librispeech/authors/dev-clean-M.txt\") as f:\n",
    "    male_dev = f.read().strip().split('\\n')\n",
    "\n",
    "male_spkrs = [Hdf5Iterator(hdf5_path=librispeech_dev, speaker_keys=[dev], shape=(None,)) for dev in male_dev]\n",
    "male_spkrs_slice = [Hdf5Iterator(hdf5_path=librispeech_dev, speaker_keys=[dev], shape=(num_steps,)) for dev in male_dev]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "spkr_models = []\n",
    "for i, spkr in enumerate(female_spkrs):\n",
    "    print(\"Speaker\", i)\n",
    "    w = None\n",
    "    for example in islice(spkr,45):\n",
    "        mag, phases = scale_spectrogram(example)\n",
    "        try:\n",
    "            w, h = snmf(mag.T, num_components, sparsity=sparsity, num_iters=10, W_init=w)\n",
    "        except ValueError:\n",
    "            print(\"ValueError encountered\", file=sys.stderr)\n",
    "            continue\n",
    "        \n",
    "    plt.figure(figsize=(14,5))\n",
    "    plt.subplot(1,3,1)\n",
    "    plt.imshow((w @ h)[:,:100], cmap='bone', origin='lower', aspect=1/4)\n",
    "    plt.subplot(1,3,2)\n",
    "    plt.imshow(mag.T[:,:100], cmap='bone', origin='lower', aspect=1/4)\n",
    "    plt.subplot(1,3,3)\n",
    "    plt.imshow(w.T, cmap='bone', origin='lower', aspect=6)\n",
    "    plt.show()\n",
    "    spkr_models.append((w,h))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference\n",
    "\n",
    "Inference retrains just the loadings matrix $H$ in light of a given $W$ and $X$. The resulting reconstructions are qualitatively quite cruddy. Not sure what is up?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Inference on women speakers\n",
    "for i in range(5):\n",
    "    spkr_i = np.random.randint(len(female_spkrs))\n",
    "    spkr_j = np.random.randint(len(female_spkrs))\n",
    "    if spkr_i == spkr_j:\n",
    "        continue\n",
    "    \n",
    "    example_i = next(female_spkrs_slice[spkr_i])\n",
    "    example_j = next(female_spkrs_slice[spkr_j])\n",
    "    \n",
    "    mix = example_i + example_j\n",
    "    mix_scl_mag, mix_scl_phs = scale_spectrogram(mix)\n",
    "    \n",
    "    # separate\n",
    "    reco_i, reco_j = nmf_separate(mix_scl_mag.T, [spkr_models[spkr_i], spkr_models[spkr_j]], mask=True)\n",
    "    \n",
    "    plt.figure(figsize=(14,5))\n",
    "    plt.subplot(1,3,1)\n",
    "    plt.imshow(mix_scl_mag.T, cmap='bone', origin='lower', aspect=1/4)\n",
    "    plt.subplot(1,3,2)\n",
    "    plt.imshow(reco_i, cmap='bone', origin='lower', aspect=1/4)\n",
    "    plt.subplot(1,3,3)\n",
    "    plt.imshow(reco_j, cmap='bone', origin='lower', aspect=1/4)\n",
    "    plt.show()\n",
    "    \n",
    "    display.display(display.Audio(reconstruct(reco_i.T**2, mix, 10000, None, 0.0256), rate=10000))\n",
    "    display.display(display.Audio(reconstruct(reco_j.T**2, mix, 10000, None, 0.0256), rate=10000))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Out-of-sample inference\n",
    "\n",
    "Above technique only works when you know which set of basis vectors to select for each speaker.  For unseen speakers this is hard. One approach is just to pick the combination of dictionary entries that minimizes the reconstruction error. Unfortunately quadratic in the number of dictionary entries.\n",
    "\n",
    "(Getting the cross-correlation of each basis with the mixture and picking the top two is another idea.)\n",
    "\n",
    "(PCA on the W's also make lots of lots of sense)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Inference on men speakers\n",
    "for i in range(5):\n",
    "    print(\"Test {}\".format(i))\n",
    "    spkr_i = np.random.randint(len(male_spkrs))\n",
    "    spkr_j = np.random.randint(len(male_spkrs))\n",
    "    if spkr_i == spkr_j:\n",
    "        continue\n",
    "        \n",
    "    example_i = next(male_spkrs_slice[spkr_i])\n",
    "    example_j = next(male_spkrs_slice[spkr_j])\n",
    "\n",
    "    mix = example_i + example_j\n",
    "    mix_scl_mag, mix_scl_phs = scale_spectrogram(mix)\n",
    "\n",
    "    # loop over choices of speaker model\n",
    "    NmfSearchResult = namedtuple(\"NMFSearchResult\", ['i', 'j', 'error', 'models', 'reconstructions'])\n",
    "    optimal_pair = NmfSearchResult(0, 0, np.inf, [], [])  # i, j, error, reconstructions a and b\n",
    "    for model_i in range(num_components):\n",
    "        for model_j in range(model_i + 1, num_components):\n",
    "\n",
    "            reco_i, reco_j = nmf_separate(mix_scl_mag.T, [spkr_models[model_i], spkr_models[model_j]], mask=True)\n",
    "            \n",
    "            err = np.mean(np.abs(mix_scl_mag.T - (reco_i + reco_j)))\n",
    "            \n",
    "            if err < optimal_pair.error:\n",
    "                optimal_pair = NmfSearchResult(model_i, model_j, err, [w_i, w_j], \n",
    "                                               [reco_i, reco_j])\n",
    "                \n",
    "    # Display results\n",
    "    print(\"Used weight matrices {} and {}\".format(optimal_pair.i, optimal_pair.j))\n",
    "    \n",
    "    plt.figure(figsize=(14,5))\n",
    "    plt.subplot(1,3,1)\n",
    "    plt.imshow(mix_scl_mag.T, cmap='bone', origin='lower', aspect=1/4)\n",
    "    plt.subplot(1,3,2)\n",
    "   \n",
    "    plt.imshow(optimal_pair.reconstructions[0], cmap='bone', origin='lower', aspect=1/4)\n",
    "    plt.subplot(1,3,3)\n",
    "    plt.imshow(optimal_pair.reconstructions[1], cmap='bone', origin='lower', aspect=1/4)\n",
    "    plt.show()\n",
    "    \n",
    "    # Evaluate\n",
    "    mix_audio = reconstruct(mix, mix, 10000, None, 0.0256)\n",
    "    ref_i = reconstruct(example_i, example_i, 10000, None, 0.0256)\n",
    "    ref_j = reconstruct(example_j, example_j, 10000, None, 0.0256)\n",
    "    opt_reco_i = reconstruct(optimal_pair.reconstructions[0].T**2, mix, 10000, None, 0.0256)\n",
    "    opt_reco_j = reconstruct(optimal_pair.reconstructions[1].T**2, mix, 10000, None, 0.0256)\n",
    "\n",
    "    base_metrics =  bss_eval_sources(np.stack([ref_i, ref_j]), np.stack([mix_audio, mix_audio]))\n",
    "    predicted_metrics = bss_eval_sources(np.stack([ref_i, ref_j]), np.stack([opt_reco_i, opt_reco_j]))\n",
    "    print(\"SDR: {}, SIR: {}, SAR: {}, perm {}\".format(*base_metrics))\n",
    "    print(\"SDR: {}, SIR: {}, SAR: {}, perm {}\".format(*predicted_metrics))\n",
    "    \n",
    "    display.display(display.Audio(mix_audio, rate=10000))\n",
    "    display.display(display.Audio(opt_reco_i, rate=10000))\n",
    "    display.display(display.Audio(opt_reco_j, rate=10000))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "spkr_models"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [magnolia3]",
   "language": "python",
   "name": "Python [magnolia3]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
